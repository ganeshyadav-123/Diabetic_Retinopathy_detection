{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diabetic Retinopathy Detection using ResNet with Attention Mechanism\n",
        "\n",
        "This notebook implements a deep learning model for diabetic retinopathy detection using ResNet architecture with attention mechanism. The dataset contains 5 classes of diabetic retinopathy severity levels.\n",
        "\n",
        "## Dataset Classes:\n",
        "- **No_DR**: No diabetic retinopathy (1805 images)\n",
        "- **Mild**: Mild diabetic retinopathy (370 images)\n",
        "- **Moderate**: Moderate diabetic retinopathy (999 images)\n",
        "- **Severe**: Severe diabetic retinopathy (193 images)\n",
        "- **Proliferate_DR**: Proliferative diabetic retinopathy (295 images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Deep Learning Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50, ResNet50_Weights\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Dataset Configuration and Data Loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset configuration\n",
        "DATA_DIR = '/Users/landaganesh/Documents/Projects /Miniproject/colored_images'\n",
        "CLASSES = ['No_DR', 'Mild', 'Moderate', 'Severe', 'Proliferate_DR']\n",
        "NUM_CLASSES = len(CLASSES)\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"Classes: {CLASSES}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset mapping\n",
        "def create_dataset_mapping(data_dir, classes):\n",
        "    \"\"\"\n",
        "    Create a mapping of image paths to their corresponding labels\n",
        "    \"\"\"\n",
        "    data = []\n",
        "    \n",
        "    for class_idx, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if os.path.exists(class_dir):\n",
        "            for img_file in os.listdir(class_dir):\n",
        "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(class_dir, img_file)\n",
        "                    data.append({\n",
        "                        'image_path': img_path,\n",
        "                        'label': class_idx,\n",
        "                        'class_name': class_name\n",
        "                    })\n",
        "    \n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Create dataset\n",
        "df = create_dataset_mapping(DATA_DIR, CLASSES)\n",
        "print(f\"Total images: {len(df)}\")\n",
        "print(f\"\\nClass distribution:\")\n",
        "print(df['class_name'].value_counts())\n",
        "\n",
        "# Display sample data\n",
        "print(f\"\\nSample data:\")\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "class_counts = df['class_name'].value_counts()\n",
        "plt.bar(class_counts.index, class_counts.values, color=['skyblue', 'lightcoral', 'lightgreen', 'orange', 'purple'])\n",
        "plt.title('Class Distribution in Dataset')\n",
        "plt.xlabel('Diabetic Retinopathy Classes')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate class weights for handling imbalanced data\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(df['label']), y=df['label'])\n",
        "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
        "print(f\"\\nClass weights: {class_weights}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Custom Dataset Class and Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class DiabeticRetinopathyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class for diabetic retinopathy images\n",
        "    \"\"\"\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.dataframe.iloc[idx]['image_path']\n",
        "        label = self.dataframe.iloc[idx]['label']\n",
        "        \n",
        "        # Load image\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            # Return a black image if loading fails\n",
        "            image = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# Define data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Data transforms defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train-Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the dataset into train and validation sets\n",
        "train_df, val_df = train_test_split(\n",
        "    df, \n",
        "    test_size=0.2, \n",
        "    random_state=42, \n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = DiabeticRetinopathyDataset(train_df, transform=train_transform)\n",
        "val_dataset = DiabeticRetinopathyDataset(val_df, transform=val_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=True, \n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=BATCH_SIZE, \n",
        "    shuffle=False, \n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Data loaders created successfully!\")\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Attention Mechanism Implementation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ChannelAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Channel Attention Module\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
        "        )\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        avg_out = self.fc(self.avg_pool(x))\n",
        "        max_out = self.fc(self.max_pool(x))\n",
        "        out = avg_out + max_out\n",
        "        return self.sigmoid(out)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatial Attention Module\n",
        "    \"\"\"\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super(SpatialAttention, self).__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        x = torch.cat([avg_out, max_out], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return self.sigmoid(x)\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolutional Block Attention Module (CBAM)\n",
        "    Combines Channel and Spatial Attention\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
        "        super(CBAM, self).__init__()\n",
        "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
        "        self.spatial_attention = SpatialAttention(kernel_size)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Apply channel attention\n",
        "        x = x * self.channel_attention(x)\n",
        "        # Apply spatial attention\n",
        "        x = x * self.spatial_attention(x)\n",
        "        return x\n",
        "\n",
        "print(\"Attention mechanisms defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ResNet with Attention Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNetWithAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet50 with CBAM attention mechanism for diabetic retinopathy detection\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=5, pretrained=True):\n",
        "        super(ResNetWithAttention, self).__init__()\n",
        "        \n",
        "        # Load pretrained ResNet50\n",
        "        if pretrained:\n",
        "            self.backbone = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "        else:\n",
        "            self.backbone = resnet50(weights=None)\n",
        "        \n",
        "        # Get the number of input features for the classifier\n",
        "        num_features = self.backbone.fc.in_features\n",
        "        \n",
        "        # Remove the original classifier\n",
        "        self.backbone = nn.Sequential(*list(self.backbone.children())[:-2])\n",
        "        \n",
        "        # Add attention modules after each residual block\n",
        "        self.attention1 = CBAM(256, reduction=16)  # After layer2\n",
        "        self.attention2 = CBAM(512, reduction=16)  # After layer3\n",
        "        self.attention3 = CBAM(1024, reduction=16) # After layer4\n",
        "        \n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        \n",
        "        # Classifier with dropout for regularization\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2048, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Extract features using ResNet backbone\n",
        "        x = self.backbone.conv1(x)\n",
        "        x = self.backbone.bn1(x)\n",
        "        x = self.backbone.relu(x)\n",
        "        x = self.backbone.maxpool(x)\n",
        "        \n",
        "        # Layer 1\n",
        "        x = self.backbone.layer1(x)\n",
        "        \n",
        "        # Layer 2 with attention\n",
        "        x = self.backbone.layer2(x)\n",
        "        x = self.attention1(x)\n",
        "        \n",
        "        # Layer 3 with attention\n",
        "        x = self.backbone.layer3(x)\n",
        "        x = self.attention2(x)\n",
        "        \n",
        "        # Layer 4 with attention\n",
        "        x = self.backbone.layer4(x)\n",
        "        x = self.attention3(x)\n",
        "        \n",
        "        # Global average pooling\n",
        "        x = self.global_avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        # Classification\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Create model\n",
        "model = ResNetWithAttention(num_classes=NUM_CLASSES, pretrained=True)\n",
        "model = model.to(device)\n",
        "\n",
        "# Print model summary\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"Model created successfully!\")\n",
        "\n",
        "# Test model with a sample input\n",
        "sample_input = torch.randn(1, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
        "with torch.no_grad():\n",
        "    sample_output = model(sample_input)\n",
        "print(f\"Sample output shape: {sample_output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    mode='min', \n",
        "    factor=0.5, \n",
        "    patience=5, \n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"Loss function: CrossEntropyLoss with class weights\")\n",
        "print(f\"Optimizer: Adam with learning rate {LEARNING_RATE}\")\n",
        "print(f\"Scheduler: ReduceLROnPlateau\")\n",
        "print(f\"Training configuration completed!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Training and Validation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
        "    \"\"\"\n",
        "    Train the model for one epoch\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "        \n",
        "        if batch_idx % 50 == 0:\n",
        "            print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"\n",
        "    Validate the model for one epoch\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in val_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "            \n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc, all_predictions, all_targets\n",
        "\n",
        "print(\"Training and validation functions defined successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Training Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize training history\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "best_val_acc = 0.0\n",
        "best_model_state = None\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Training for {EPOCHS} epochs\")\n",
        "print(f\"Device: {device}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    print(\"-\" * 30)\n",
        "    \n",
        "    # Training\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    \n",
        "    # Validation\n",
        "    val_loss, val_acc, val_predictions, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    # Update learning rate\n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Store metrics\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    # Save best model\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        best_model_state = model.state_dict().copy()\n",
        "        print(f\"New best validation accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Print epoch results\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "    \n",
        "    # Early stopping check (optional)\n",
        "    if epoch > 10 and val_acc < max(val_accuracies[-10:]) - 5:\n",
        "        print(\"Early stopping triggered!\")\n",
        "        break\n",
        "\n",
        "print(\"\\nTraining completed!\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Load Best Model and Evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model\n",
        "if best_model_state is not None:\n",
        "    model.load_state_dict(best_model_state)\n",
        "    print(\"Best model loaded!\")\n",
        "\n",
        "# Final evaluation\n",
        "print(\"\\nFinal evaluation on validation set...\")\n",
        "val_loss, val_acc, val_predictions, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "\n",
        "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n",
        "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(val_targets, val_predictions, target_names=CLASSES))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Visualization of Training Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(train_losses, label='Training Loss', color='blue')\n",
        "ax1.plot(val_losses, label='Validation Loss', color='red')\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(train_accuracies, label='Training Accuracy', color='blue')\n",
        "ax2.plot(val_accuracies, label='Validation Accuracy', color='red')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Confusion Matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(val_targets, val_predictions)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=CLASSES, yticklabels=CLASSES)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n",
        "\n",
        "# Calculate per-class accuracy\n",
        "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
        "print(\"\\nPer-class Accuracy:\")\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    print(f\"{class_name}: {class_accuracies[i]:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Sample Predictions Visualization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_predictions(model, val_loader, class_names, num_samples=8):\n",
        "    \"\"\"\n",
        "    Visualize sample predictions\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    \n",
        "    # Get a batch of validation data\n",
        "    data_iter = iter(val_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    \n",
        "    # Move to device\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        probabilities = F.softmax(outputs, dim=1)\n",
        "    \n",
        "    # Move back to CPU for visualization\n",
        "    images = images.cpu()\n",
        "    labels = labels.cpu()\n",
        "    predicted = predicted.cpu()\n",
        "    probabilities = probabilities.cpu()\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "    axes = axes.ravel()\n",
        "    \n",
        "    for i in range(min(num_samples, len(images))):\n",
        "        # Denormalize image for display\n",
        "        img = images[i]\n",
        "        img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
        "        img = img + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
        "        img = torch.clamp(img, 0, 1)\n",
        "        img = img.permute(1, 2, 0)\n",
        "        \n",
        "        # Plot image\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f'True: {class_names[labels[i]]}\\nPred: {class_names[predicted[i]]}\\nConf: {probabilities[i][predicted[i]]:.3f}')\n",
        "        axes[i].axis('off')\n",
        "        \n",
        "        # Color code the title based on correctness\n",
        "        if labels[i] == predicted[i]:\n",
        "            axes[i].title.set_color('green')\n",
        "        else:\n",
        "            axes[i].title.set_color('red')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize sample predictions\n",
        "print(\"Sample Predictions:\")\n",
        "visualize_predictions(model, val_loader, CLASSES, num_samples=8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model\n",
        "model_save_path = '/Users/landaganesh/Documents/Projects /Miniproject/diabetic_retinopathy_model.pth'\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'class_names': CLASSES,\n",
        "    'num_classes': NUM_CLASSES,\n",
        "    'img_size': IMG_SIZE,\n",
        "    'best_val_acc': best_val_acc,\n",
        "    'training_history': {\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies\n",
        "    }\n",
        "}, model_save_path)\n",
        "\n",
        "print(f\"Model saved to: {model_save_path}\")\n",
        "print(f\"Model includes:\")\n",
        "print(f\"- Model weights\")\n",
        "print(f\"- Class names: {CLASSES}\")\n",
        "print(f\"- Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"- Image size: {IMG_SIZE}\")\n",
        "print(f\"- Best validation accuracy: {best_val_acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Model Summary and Performance Metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print final summary\n",
        "print(\"=\" * 60)\n",
        "print(\"DIABETIC RETINOPATHY DETECTION MODEL SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Dataset: {len(df)} total images\")\n",
        "print(f\"Classes: {CLASSES}\")\n",
        "print(f\"Training samples: {len(train_df)}\")\n",
        "print(f\"Validation samples: {len(val_df)}\")\n",
        "print(f\"Model: ResNet50 with CBAM Attention\")\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Epochs trained: {len(train_losses)}\")\n",
        "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "print(f\"Final validation accuracy: {val_acc:.2f}%\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Print class-wise performance\n",
        "print(\"\\nCLASS-WISE PERFORMANCE:\")\n",
        "print(\"-\" * 30)\n",
        "for i, class_name in enumerate(CLASSES):\n",
        "    print(f\"{class_name}: {class_accuracies[i]:.3f} accuracy\")\n",
        "\n",
        "print(\"\\nTraining completed successfully!\")\n",
        "print(f\"Model saved to: {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
