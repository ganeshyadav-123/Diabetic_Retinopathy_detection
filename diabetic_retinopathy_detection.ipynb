{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy Detection using ResNet with Attention Mechanism\n",
    "\n",
    "This notebook implements a deep learning model for diabetic retinopathy detection using ResNet architecture with attention mechanism. The dataset contains 5 classes of diabetic retinopathy severity levels.\n",
    "\n",
    "## Dataset Classes:\n",
    "- **No_DR**: No diabetic retinopathy (1805 images)\n",
    "- **Mild**: Mild diabetic retinopathy (370 images)\n",
    "- **Moderate**: Moderate diabetic retinopathy (999 images)\n",
    "- **Severe**: Severe diabetic retinopathy (193 images)\n",
    "- **Proliferate_DR**: Proliferative diabetic retinopathy (295 images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.4)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install pandas\n",
    "!pip3 install matplotlib\n",
    "!pip3 install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context  # temporary fix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (0.24.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torchvision) (2.3.4)\n",
      "Requirement already satisfied: torch==2.9.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torchvision) (2.9.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from torch==2.9.0->torchvision) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.14/lib/python3.14/site-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Configuration and Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 5\n",
      "Classes: ['No_DR', 'Mild', 'Moderate', 'Severe', 'Proliferate_DR']\n"
     ]
    }
   ],
   "source": [
    "# Dataset configuration\n",
    "DATA_DIR = '/Users/landaganesh/Documents/Projects /Miniproject/colored_images'\n",
    "CLASSES = ['No_DR', 'Mild', 'Moderate', 'Severe', 'Proliferate_DR']\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Classes: {CLASSES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 3662\n",
      "\n",
      "Class distribution:\n",
      "class_name\n",
      "No_DR             1805\n",
      "Moderate           999\n",
      "Mild               370\n",
      "Proliferate_DR     295\n",
      "Severe             193\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample data:\n",
      "                                          image_path  label class_name\n",
      "0  /Users/landaganesh/Documents/Projects /Minipro...      0      No_DR\n",
      "1  /Users/landaganesh/Documents/Projects /Minipro...      0      No_DR\n",
      "2  /Users/landaganesh/Documents/Projects /Minipro...      0      No_DR\n",
      "3  /Users/landaganesh/Documents/Projects /Minipro...      0      No_DR\n",
      "4  /Users/landaganesh/Documents/Projects /Minipro...      0      No_DR\n"
     ]
    }
   ],
   "source": [
    "# Create dataset mapping\n",
    "def create_dataset_mapping(data_dir, classes):\n",
    "    \"\"\"\n",
    "    Create a mapping of image paths to their corresponding labels\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for class_idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        if os.path.exists(class_dir):\n",
    "            for img_file in os.listdir(class_dir):\n",
    "                if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, img_file)\n",
    "                    data.append({\n",
    "                        'image_path': img_path,\n",
    "                        'label': class_idx,\n",
    "                        'class_name': class_name\n",
    "                    })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Create dataset\n",
    "df = create_dataset_mapping(DATA_DIR, CLASSES)\n",
    "print(f\"Total images: {len(df)}\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(df['class_name'].value_counts())\n",
    "\n",
    "# Display sample data\n",
    "print(f\"\\nSample data:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class weights: [0.40576177 1.97945946 0.73313313 3.79481865 2.48271186]\n"
     ]
    }
   ],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "class_counts = df['class_name'].value_counts()\n",
    "plt.bar(class_counts.index, class_counts.values, color=['skyblue', 'lightcoral', 'lightgreen', 'orange', 'purple'])\n",
    "plt.title('Class Distribution in Dataset')\n",
    "plt.xlabel('Diabetic Retinopathy Classes')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate class weights for handling imbalanced data\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(df['label']), y=df['label'])\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "print(f\"\\nClass weights: {class_weights}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Custom Dataset Class and Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transforms defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class DiabeticRetinopathyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for diabetic retinopathy images\n",
    "    \"\"\"\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['image_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a black image if loading fails\n",
    "            image = Image.new('RGB', (IMG_SIZE, IMG_SIZE), (0, 0, 0))\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Define data transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data transforms defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 2929\n",
      "Validation samples: 733\n",
      "Data loaders created successfully!\n",
      "Training batches: 92\n",
      "Validation batches: 23\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train and validation sets\n",
    "train_df, val_df = train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df['label']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = DiabeticRetinopathyDataset(train_df, transform=train_transform)\n",
    "val_dataset = DiabeticRetinopathyDataset(val_df, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=0  # add this line or change it to 0 if it exists\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    num_workers=0  # add this line or change it to 0 if it exists\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Data loaders created successfully!\")\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Attention Mechanism Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention mechanisms defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class ChannelAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Channel Attention Module\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Spatial Attention Module\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        x = torch.cat([avg_out, max_out], dim=1)\n",
    "        x = self.conv(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Block Attention Module (CBAM)\n",
    "    Combines Channel and Spatial Attention\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Apply channel attention\n",
    "        x = x * self.channel_attention(x)\n",
    "        # Apply spatial attention\n",
    "        x = x * self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "print(\"Attention mechanisms defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ResNet with Attention Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl, certifi\n",
    "\n",
    "# Use certifi's CA bundle for verified contexts\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "ssl._create_default_https_context = lambda *args, **kwargs: ssl_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 403\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import certifi\n",
    "\n",
    "url = \"https://download.pytorch.org\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, verify=certifi.where())\n",
    "\n",
    "print(\"Status code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model and training setup complete.\n",
      "Output shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Device setup for Apple Silicon MPS (Mac M1/M2)\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define CBAM module (Convolutional Block Attention Module)\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels, reduction_ratio=16, kernel_size=7):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channels = channels\n",
    "\n",
    "        # Channel Attention\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction_ratio, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels // reduction_ratio, channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid_channel = nn.Sigmoid()\n",
    "\n",
    "        # Spatial Attention\n",
    "        self.conv_spatial = nn.Conv2d(2, 1, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.sigmoid_spatial = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Channel Attention\n",
    "        b, c, h, w = x.size()\n",
    "        avg_pool = self.avg_pool(x).view(b, c)\n",
    "        max_pool = self.max_pool(x).view(b, c)\n",
    "\n",
    "        avg_out = self.mlp(avg_pool)\n",
    "        max_out = self.mlp(max_pool)\n",
    "\n",
    "        channel_attn = self.sigmoid_channel(avg_out + max_out).view(b, c, 1, 1)\n",
    "        x = x * channel_attn.expand_as(x)\n",
    "\n",
    "        # Spatial Attention\n",
    "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
    "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
    "        spatial_attn = torch.cat([avg_out, max_out], dim=1)\n",
    "        spatial_attn = self.sigmoid_spatial(self.conv_spatial(spatial_attn))\n",
    "        x = x * spatial_attn.expand_as(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Define the full model with ResNet50 backbone and CBAM attention\n",
    "class ResNetWithAttention(nn.Module):\n",
    "    def __init__(self, num_classes=5, pretrained=True):\n",
    "        super(ResNetWithAttention, self).__init__()\n",
    "        weights = ResNet50_Weights.IMAGENET1K_V2 if pretrained else None\n",
    "        backbone = resnet50(weights=weights)\n",
    "\n",
    "        # Use backbone layers explicitly\n",
    "        self.conv1 = backbone.conv1\n",
    "        self.bn1 = backbone.bn1\n",
    "        self.relu = backbone.relu\n",
    "        self.maxpool = backbone.maxpool\n",
    "        self.layer1 = backbone.layer1  # 256 channels\n",
    "        self.layer2 = backbone.layer2  # 512 channels\n",
    "        self.layer3 = backbone.layer3  # 1024 channels\n",
    "        self.layer4 = backbone.layer4  # 2048 channels\n",
    "\n",
    "        # CBAM attention modules with correct channel numbers\n",
    "        self.attention1 = CBAM(256)    # layer1 output channels\n",
    "        self.attention2 = CBAM(512)    # layer2 output channels\n",
    "        self.attention3 = CBAM(1024)   # layer3 output channels\n",
    "        self.attention4 = CBAM(2048)   # layer4 output channels\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.attention1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.attention2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.attention3(x)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "        x = self.attention4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "num_classes = 5\n",
    "model = ResNetWithAttention(num_classes=num_classes, pretrained=True).to(device)\n",
    "\n",
    "# Optimizer, Loss, Scheduler example\n",
    "LEARNING_RATE = 1e-4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "print(\"Model and training setup complete.\")\n",
    "\n",
    "# Dummy test input to check if model runs correctly on MPS\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(device)\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "print(\"Output shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: CrossEntropyLoss with class weights\n",
      "Optimizer: Adam with learning rate 0.0001\n",
      "Scheduler: ReduceLROnPlateau\n",
      "Training configuration completed!\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    factor=0.5, \n",
    "    patience=5\n",
    ")\n",
    "\n",
    "print(f\"Loss function: CrossEntropyLoss with class weights\")\n",
    "print(f\"Optimizer: Adam with learning rate {LEARNING_RATE}\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau\")\n",
    "print(f\"Training configuration completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Training and Validation Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f'Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model for one epoch\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_targets\n",
    "\n",
    "print(\"Training and validation functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Training Loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Starting training...\n",
      "Training for 20 epochs\n",
      "--------------------------------------------------\n",
      "\n",
      "Epoch 1/20\n",
      "------------------------------\n",
      "Batch 0/92, Loss: 1.6054\n",
      "Batch 50/92, Loss: 1.5997\n",
      "New best validation accuracy: 52.93%\n",
      "Train Loss: 1.5603, Train Acc: 51.49%\n",
      "Val Loss: 1.5434, Val Acc: 52.93%\n",
      "Current LR: 0.000100\n",
      "\n",
      "Epoch 2/20\n",
      "------------------------------\n",
      "Batch 0/92, Loss: 1.4740\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "best_val_acc = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "device = torch.device(\"cpu\")  # Force CPU usage\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)  # Move model to CPU\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Training for {EPOCHS} epochs\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc, val_predictions, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
    "    \n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "    print(f\"Current LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    if epoch > 10 and val_acc < max(val_accuracies[-10:]) - 5:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Load Best Model and Evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(\"Best model loaded!\")\n",
    "\n",
    "# Final evaluation\n",
    "print(\"\\nFinal evaluation on validation set...\")\n",
    "val_loss, val_acc, val_predictions, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Final Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(val_targets, val_predictions, target_names=CLASSES))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Visualization of Training Progress\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(train_losses, label='Training Loss', color='blue')\n",
    "ax1.plot(val_losses, label='Validation Loss', color='red')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(train_accuracies, label='Training Accuracy', color='blue')\n",
    "ax2.plot(val_accuracies, label='Validation Accuracy', color='red')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Confusion Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(val_targets, val_predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for i, class_name in enumerate(CLASSES):\n",
    "    print(f\"{class_name}: {class_accuracies[i]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Sample Predictions Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, val_loader, class_names, num_samples=8):\n",
    "    \"\"\"\n",
    "    Visualize sample predictions\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get a batch of validation data\n",
    "    data_iter = iter(val_loader)\n",
    "    images, labels = next(data_iter)\n",
    "    \n",
    "    # Move to device\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "    \n",
    "    # Move back to CPU for visualization\n",
    "    images = images.cpu()\n",
    "    labels = labels.cpu()\n",
    "    predicted = predicted.cpu()\n",
    "    probabilities = probabilities.cpu()\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for i in range(min(num_samples, len(images))):\n",
    "        # Denormalize image for display\n",
    "        img = images[i]\n",
    "        img = img * torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "        img = img + torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        img = img.permute(1, 2, 0)\n",
    "        \n",
    "        # Plot image\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'True: {class_names[labels[i]]}\\nPred: {class_names[predicted[i]]}\\nConf: {probabilities[i][predicted[i]]:.3f}')\n",
    "        axes[i].axis('off')\n",
    "        \n",
    "        # Color code the title based on correctness\n",
    "        if labels[i] == predicted[i]:\n",
    "            axes[i].title.set_color('green')\n",
    "        else:\n",
    "            axes[i].title.set_color('red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample predictions\n",
    "print(\"Sample Predictions:\")\n",
    "visualize_predictions(model, val_loader, CLASSES, num_samples=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = '/Users/landaganesh/Documents/Projects /Miniproject/diabetic_retinopathy_model.pth'\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'class_names': CLASSES,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'img_size': IMG_SIZE,\n",
    "    'best_val_acc': best_val_acc,\n",
    "    'training_history': {\n",
    "        'train_losses': train_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies\n",
    "    }\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to: {model_save_path}\")\n",
    "print(f\"Model includes:\")\n",
    "print(f\"- Model weights\")\n",
    "print(f\"- Class names: {CLASSES}\")\n",
    "print(f\"- Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"- Image size: {IMG_SIZE}\")\n",
    "print(f\"- Best validation accuracy: {best_val_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Model Summary and Performance Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"DIABETIC RETINOPATHY DETECTION MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Dataset: {len(df)} total images\")\n",
    "print(f\"Classes: {CLASSES}\")\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Validation samples: {len(val_df)}\")\n",
    "print(f\"Model: ResNet50 with CBAM Attention\")\n",
    "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Epochs trained: {len(train_losses)}\")\n",
    "print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "print(f\"Final validation accuracy: {val_acc:.2f}%\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Print class-wise performance\n",
    "print(\"\\nCLASS-WISE PERFORMANCE:\")\n",
    "print(\"-\" * 30)\n",
    "for i, class_name in enumerate(CLASSES):\n",
    "    print(f\"{class_name}: {class_accuracies[i]:.3f} accuracy\")\n",
    "\n",
    "print(\"\\nTraining completed successfully!\")\n",
    "print(f\"Model saved to: {model_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
